[
  {
    "objectID": "blog/index.html",
    "href": "blog/index.html",
    "title": "Blog",
    "section": "",
    "text": "Welcome to my blog! Here I share insights on privacy, security, and AI research. I talk about related books and articles I read on the subject, and introduce my own work.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nYour Faces blong to Us: Book review through the lens of Trustwortht AI\n\n\n\n\n\n\nFace recognition\n\n\nExplainability\n\n\nmachine learning\n\n\nethics\n\n\n\n\n\n\n\n\n\nAug 18, 2025\n\n\nMaryam Babaei\n\n\n\n\n\n\nNo matching items",
    "crumbs": [
      "Blog"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Welcome!",
    "section": "",
    "text": "I am Maryam Babaei, a PhD student at TISL Lab at ETS. I am doing my research on Privacy and Security risks of post-hoc explananations under supervision of Ulrich Aïvodji at ETS and Sébastien Gambs at UQAM.\nI am also a student member at NSERC CREATE - Responsible Development of Artificial Intelligence and Mila\nMy commitment to security, privacy, and ethical machine learning research has been shaped by my personal, academic, and professional experiences. With my background in addressing user privacy concerns and understanding the intricacies of data processing systems, I am committed to ensuring that advancements in AI adhere to strong ethical principles.\nMy thesis focuses on finding privacy and security risks of post-hoc explanations in machine learning models. I aim to identify vulnerabilities and propose solutions to mitigate these risks, ensuring safer and more reliable AI systems. I also try to look for unexploited vulnerabilities and perform novel attacks leveraging these vulnerabilities to gin the attention of researchers to the importance of mitigating these vulnerabilities. I will share my other contributions in the Research section.",
    "crumbs": [
      "Home"
    ]
  },
  {
    "objectID": "research.html",
    "href": "research.html",
    "title": "Maryam Babaei",
    "section": "",
    "text": "Under Construction"
  },
  {
    "objectID": "blog/posts/index.html",
    "href": "blog/posts/index.html",
    "title": "Your Faces blong to Us: Book review through the lens of Trustwortht AI",
    "section": "",
    "text": "This book is not just a book; it is a wake-up call. Hill, a journalist at The New York Times, investigates the rise of Clearview AI, a company that scraped billions of images from the internet to build a powerful facial recognition tool. Starting with how incorrect image classification affected innocent lives, she explores the broader societal impact of deploying such technology without robust safeguards.\nThe book details how this technology challenges our notions of privacy and consent, raising urgent questions about the ethical use of AI and exposing the risks of unchecked surveillance. She also provides an engaging review of the history of image recognition and visual classification tasks, even before the rise of AI, which is especially interesting for people in the field.\nHill then discusses the ethical concerns of having facial recognition systems in place, including their access to data people share with the government, on social media, or even images shared of them without their knowledge. She questions the validity of governments having these tools at their disposal and their effect on people’s lives.\nShe also highlights the existing bias in these services. By following the people behind Clearview and sharing the stories of the victims affected by their services, Hill brings human stories to our attention and emphasizes the bias and other harms hidden in these technologies. This prompts us to consider the main question we should ask ourselves before using or creating any new technology: “Just because a technology is possible, should it be built? Clearview answered ‘yes’ without hesitation, forcing the rest of us to struggle with the fallout.”\n\nPersonal Reflection\n\nI think reading this book is a must. It makes you unsettled, yet informed and alert. The stories and analysis presented by Hill encourage readers to critically evaluate the impact of AI technologies on society and personal privacy. This book is essential for anyone interested in the intersection of technology, ethics, and human rights. Your Face Belongs to Us is a powerful, necessary read. It exposes the hidden players shaping a future where anonymity might be impossible.\n\nSpoiler alert: Are you interested in political campaigns and their background? This book reveals some connections between Clearview founders and US election campaigns in 2016."
  },
  {
    "objectID": "blog/posts/index.html#your-faces-blong-to-us-book-review-through-the-lens-of-trustwortht-ai",
    "href": "blog/posts/index.html#your-faces-blong-to-us-book-review-through-the-lens-of-trustwortht-ai",
    "title": "Your Faces blong to Us: Book review through the lens of Trustwortht AI",
    "section": "",
    "text": "This book is not just a book; it is a wake-up call. Hill, a journalist at The New York Times, investigates the rise of Clearview AI, a company that scraped billions of images from the internet to build a powerful facial recognition tool. Starting with how incorrect image classification affected innocent lives, she explores the broader societal impact of deploying such technology without robust safeguards.\nThe book details how this technology challenges our notions of privacy and consent, raising urgent questions about the ethical use of AI and exposing the risks of unchecked surveillance. She also provides an engaging review of the history of image recognition and visual classification tasks, even before the rise of AI, which is especially interesting for people in the field.\nHill then discusses the ethical concerns of having facial recognition systems in place, including their access to data people share with the government, on social media, or even images shared of them without their knowledge. She questions the validity of governments having these tools at their disposal and their effect on people’s lives.\nShe also highlights the existing bias in these services. By following the people behind Clearview and sharing the stories of the victims affected by their services, Hill brings human stories to our attention and emphasizes the bias and other harms hidden in these technologies. This prompts us to consider the main question we should ask ourselves before using or creating any new technology: “Just because a technology is possible, should it be built? Clearview answered ‘yes’ without hesitation, forcing the rest of us to struggle with the fallout.”\n\nPersonal Reflection\n\nI think reading this book is a must. It makes you unsettled, yet informed and alert. The stories and analysis presented by Hill encourage readers to critically evaluate the impact of AI technologies on society and personal privacy. This book is essential for anyone interested in the intersection of technology, ethics, and human rights. Your Face Belongs to Us is a powerful, necessary read. It exposes the hidden players shaping a future where anonymity might be impossible.\n\nSpoiler alert: Are you interested in political campaigns and their background? This book reveals some connections between Clearview founders and US election campaigns in 2016."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site"
  }
]